<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Web AeTimeline</title>
    <!-- vconsole -->
    <script src="https://unpkg.com/vconsole/dist/vconsole.min.js"></script>
    <script type="text/javascript">
        new VConsole()
    </script>    
</head>

<body>
    <div>
        <div>
            <button disabled id="playbackBtn" style="height:44px">播放</button>
        </div>
        <div>
            <canvas id="canvas" class="video"></canvas>
            <canvas id="canvasRaw" style="display:none;"></canvas>
            <!-- <audio id="audio" preload="auto">
                <source src="1989392.mp3" type="audio/mp3">
            </audio> -->
        </div>
    </div>
    <script src="./AeTimeline.js"></script>    
    <script type='text/javascript'>
        window.addEventListener("wasmLoaded", () => {
            console.log("wasmLoaded")
            Module._AEWebInit();
            playbackBtn.disabled = false;
        });
        var faceImgBuffer = null;
        var texture = null;
        var mWidth  = 720;
        var mHeight = 1280;
        var textureId = null;
        var nowPlayTime = 0;
        var audio = null;
        var audioPCMData = null;
        var loadStartTime = -1;

        const gl = document.getElementById('canvas').getContext("webgl");
        // Only continue if WebGL is available and working
        if (gl === null) {
            alert("Unable to initialize WebGL. Your browser or machine may not support it.");
        }

        //https://github.com/emscripten-core/emscripten/issues/6103
        function RegisterNativeTextureId(textureResource){
            var id = GL.getNewId(GL.textures); // already included in code generated by emscripten
            textureResource.name = id;
            GL.textures[id] = textureResource;

            return id;
        }

        function UnregisterNativeTextureId(nativeTextureId){
            var tex = GL.textures[nativeTextureId];

            tex.name = 0;
            GL.textures[nativeTextureId] = null;

            return tex;
        }

        //帧率统计
        var frameCnt = 0;
        var timeElapsed = 0;
        var lastTime = 0;
        function calcFPS(){
            frameCnt++;

            let fps = 0;
            let timeDelta = 0;
            const currentTime = performance.now();

            if (lastTime) {
                timeDelta = currentTime - lastTime;
                fps = Math.round(1000/((currentTime - lastTime)));
            }
            lastTime = currentTime;
            timeElapsed +=timeDelta;

            if(timeElapsed >= 5000){
                fps = Math.round(frameCnt*1000/timeElapsed);
                timeElapsed = 0;
                frameCnt =0;
                console.log('FPS:'+fps);
            }
         }

        
        function render() {
            calcFPS();
            // if(window.audioContext != null) {
            //     const ts = window.audioContext.getOutputTimestamp();
            //     nowPlayTime =ts.performanceTime;//ts.contextTime*1000;
            //     //console.log("context time:" + ts.contextTime*1000 + "/" + ts.performanceTime);
            //     //nowPlayTime = audioCtx.currentTime*1000;
            // }
            // if(audio != null){
            //     nowPlayTime = audio.currentTime*1000;
            // }
            var canvasId  = 'canvas';
            var strBuffer = new TextEncoder().encode(canvasId);
            var strPointer = Module._malloc(strBuffer.length + 1);
            Module.HEAPU8.set(strBuffer, strPointer);
            Module.HEAPU8[strPointer + strBuffer.length] = 0;

            Module._AEWebMakeCurrent(strPointer);
            gl.pixelStorei(gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, true);
            //console.log('GL Error - 2: ' + gl.getError());
            Module._AERenderMV(strPointer, nowPlayTime);//        
            Module._free(strPointer);
            requestAnimationFrame(render);
        }

        window.AudioContext = window.AudioContext || window.webkitAudioContext;
        if (window.AudioContext) {
            window.audioContext = new window.AudioContext();
        }
        function fixAudioContext() {
            if (window.audioContext) {
                // Create empty buffer
                var buffer = window.audioContext.createBuffer(1, 1, 22050);
                var source = window.audioContext.createBufferSource();
                source.buffer = buffer;
                // Connect to output (speakers)
                source.connect(window.audioContext.destination);
                // Play sound
                if (source.start) {
                    source.start(0);
                } else if (source.play) {
                    source.play(0);
                } else if (source.noteOn) {
                    source.noteOn(0);
                }
            }
        }

        function playSound () {
            var context = window.audioContext;
            context.resume()
            loadStartTime = -1;
            request = new XMLHttpRequest();
            request.open("GET", "1989392.mp3", true);
            request.responseType = "arraybuffer";
            request.onload = function () {
                let audioData = request.response;
                context.decodeAudioData(
                audioData,
                function (buffer) {
                    var source = context.createBufferSource();
                    source.buffer = buffer;
                    let scriptNode = context.createScriptProcessor(4096, 2, 2);
                    source.connect(scriptNode);
                    scriptNode.connect(context.destination);
                    scriptNode.onaudioprocess = function (audioProcessingEvent) {
                        // The input buffer is the song we loaded earlier
                        let inputBuffer = audioProcessingEvent.inputBuffer;

                        // The output buffer contains the samples that will be modified and played
                        let outputBuffer = audioProcessingEvent.outputBuffer;

                        // Loop through the output channels (in this case there is only one)
                        for (
                            let channel = 0;
                            channel < outputBuffer.numberOfChannels;
                            channel++
                        ) {
                            let inputData = inputBuffer.getChannelData(channel);
                            let outputData = outputBuffer.getChannelData(channel);

                            // Loop through the 4096 samples
                            for (let sample = 0; sample < inputBuffer.length; sample++) {
                            // make output equal to the same as the input
                            outputData[sample] = inputData[sample];

                            // add noise to each output sample
                            // outputData[sample] += (Math.random() * 2 - 1) * 0.2;
                            }
                        }
                        var inputArray = inputBuffer.getChannelData(0);
                        if (audioPCMData == null){
                            audioPCMData = Module._malloc(inputArray.length * 
                            inputArray.BYTES_PER_ELEMENT);
                        }
                        Module.HEAPF32.set(inputArray, audioPCMData >> 2);
                        var curPlaybackTime = audioProcessingEvent.playbackTime * 1000;
                        if(loadStartTime == -1){
                            loadStartTime = curPlaybackTime;
                        }
                        nowPlayTime = curPlaybackTime-loadStartTime;//audioCtx.currentTime * 1000;
                        Module._AESetAudioDataFloat(audioPCMData, nowPlayTime, 1024);
                    };
                    if (source.start) {
                        source.start(0);
                    } else if (source.play) {
                        source.play(0);
                    } else if (source.noteOn) {
                        source.noteOn(0);
                    }
                },
                function (e) {
                    "Error with decoding audio data" + e.err;
                }
                );
            };
            request.send();
        }

        window.addEventListener('DOMContentLoaded', function() {            
            canvas = document.getElementById('canvas');
            audio = document.getElementById("audio");

            mWidth  = 720;
            mHeight = 1280;
            canvas.setAttribute('width', mWidth);
            canvas.setAttribute('height', mHeight);
            // fixAudioContext();
            playbackBtn.addEventListener("click", () => {
                Module._AEWebCreateMV();
                playSound();
                requestAnimationFrame(render)
                // setInterval(function(){
                //     render()
                // },1000/30);
            })                   
        });

    </script>
</body>
</html>